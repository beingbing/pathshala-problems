~~ Designing URL Shortener: Scaling It Further ~~

scaling our system for 10x

then we will be need to do sharding, for this we can do range-based partitioning. but what if, most of the urls are lying in a
single (particular) range. so, to maintain this, we not only have to make sure that the urls generated are unique but they are
symmetric also w.r.t. the range-based partitioning. which is not a good idea.

we can go for consistent hashing instead, we can further hash the shortened url in order to decide in which shard it should go.


as we already has a MS, we are not concerned about LB and backend servers.

to improve performance, we can go for cacheing as well, the ideal place will be to have cacheing at reverse proxy level (to cache
the GET request).
another level of cacheing can be done between server-DB interaction, we can use write-through cache.
the most senseble cache eviction mechanism here will be LRU cache. 