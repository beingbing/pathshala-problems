~~ Designing URL Shortener: System Design Part 1 ~~

reviewing the requirements we deduced that our system need to handle -
- roughly around 10M users
- 10:1::R:W
- 12.9GB per month (or, 150GB data per year assuming 1 year expiry)
- 6 char long unique string
- 240M active short URL at any given time
- 3 write req/second 
- 30 read req/second
- 2 or 3 Backend server replicas
- 2 or 3 DB server replicas

client interacts to create a short url of given normal url     <--->       frontend

                                                                                DB
                                ------------>     S1                 -------------------------
                                |                                    |       R1              |
                                |                                    |                       |
when client  ------>    LB  ---------------->     S2  ----------->   |         R2            |
clicks short                    |                                    |                       |
url                             |                                    |           R3          |
                                ------------>     S3                 -------------------------

we will be needing multiple DBs and servers because single DB/server can not handle these many
requests in parallel, hence, we've outlined the system design with read requests load-balanced
and connected to multiple backend servers (S1, S2, S3), and replica databases (R1, R2, R3).

Considering the global user base, we'll implement geographically scattered replicas for single-leader
replication, restricting updation to only go through leader server, ensuring uniqueness for every
short URL at DB level. One short url should not be mapped to multiple long urls.

Aiming eventual consistency hence will go with asynchronous updates to provide low latency. To
mitigate single points of failure, synchronous updates can be applied to second in leadership
line replica before allowing asynchronous updates to others.

Sharding isn't necessary due to manageable data volumes (normal hard-disk capacity is 2TB and
we are keeping 1.5TB for 10 years), and a NoSQL database like DynamoDB or Riak is suitable for
our needs.
