~~ introduction to cache ~~

If the data is not in the cache, the system retrieves it from the original source, stores it in
the cache for future requests, and then returns it to the requester. This process helps speed
up operations and reduce the load on the underlying system.It helps improve performance by
reducing the need to fetch or compute the same data repeatedly from the original source. When a
request is made for data, the system first checks the cache. If the data is found in the cache,
it is returned quickly without accessing the original source, saving time and resources. If the
data is not in the cache, the system retrieves it from the original source, stores it in the cache
for future requests, and then returns it to the requester. This process helps speed up operations
and reduce the load on the underlying system. This process is similar to memorization.

A cache is a software or hardware component that stores data to speed up retrieval and avoid
recomputation. For example, a software cache could be a map, while a hardware cache could be Redis.

A cache hit occurs when a query finds the requested data in the cache, while a cache miss occurs when
the data is not found in the cache. It's preferable to have a higher cache hit rate, meaning more
queries are satisfied from the cache rather than needing to fetch data from the original source.

Cache hit rates vary based on system requirements. Some examples include:
1. Recency bias (timeline of social networks)
2. Average over a long period (analytics results)
