~~ database reliability: replication ~~

To start our discussion with scaling our 3-tier system, Lets start with our tier
containing DB, FS and cloud storage. And discuss creation of a systemic
design to scale this tier along with ensuring compliance with other two remaining
principles of a good system design - reliability and maintainability

issues if a lot of users try to access DB, FS and cloud storage concurrently -
in terms of reliability -
1. network between backend and DB can't be established
2. power goes down
3. data become corrupt as hardware crashes

in terms of scalability -
4. processing a lot of requests concurrently - slowness

Note: we do not need to ensure maintainability of a DB server as most of the vendors do
that for us out of the box. And whatever maintainability is needed at our end is
covered under scalability.


Principle of reliability heavily hinges on mitigating issues of -
1. single point of failure
2. and also if DB goes down, what will happen to the transactions going on ?

The first strategies out there to address SPOF is -
a. replication -
we create a replica of DB in another machine.
so, when primary DB goes down, backend redirects requests to secondary DB.

addition benefits of replication apart from resolving SPOF -
 -> reduce in latency
 Latency may be high due to large distance between responding DB and requesting client.
 So, The locality of secondary DB may directly approach it instead of sending request to
 primary DB, as both of them has identical information, for them secondary DB can function
 as primary DB.

 issues with replication -
 -> what happens when we are storing new data, it needs to be stored and updated in all replicas.
    
    * synchronous updates (Consistency-oriented):
    to update new data in all the replicas and synchronize them, one approach is that the DB will
    confirm successful updation to client only when the storage/updation is successfully done on all
    the replicas.
    This ensures strong consistency, meaning that all nodes have the same up-to-date information at any
    given moment.

    problems with synchronous updates -
    - increased writing latency (Availability may be compromised)
    - what if one of the replica is down.
    for confirming if a replica is working, there needs to be a heartbeat check which continuously goes
    on, our primary DB keeps a connection with all the replicas and make sure that they are ok, as soon
    as one of them goes down, the heartbeat will stop and they will know that a replica is down.


    * asynchronous updates (Availability-oriented):
    as soon as a requests come to one of the DB in replication cluster, it will store/update and return a
    response, then asynchronously inform other replicas to make the changes.
    This results in lower latency for write operations, providing better availability and responsiveness.

    problems with asynchronous updates -
    - DB that confirmed successful updation dies down, before it could communicate to others.
    as a result user who made the change will also now access a replica but will not find the changes
    that were made.
    It violates durability part of ACID properties, which states -
    once you inform that something is done, then it should be done, user should not find later that
    it was not done.
    - there is a replication lag between DBs in cluster.
    The changes which were made might not be imediately visible to others connected with other replicas,
    but it is ok, if happens in an acceptable limits.


To remedy the updation issue within a distributed DB cluster, the most full-proof strategy is hybrid of above two -
We decide on a percentage of synchronous updation and then remaining syncing is done asynchronous.
ex - out of 5 replicas if atleast 3 of them responds ok to updation then we consider the operation is successful.

Note: the hybrid approach discussed above is an example of trade off between consistency and availability.
